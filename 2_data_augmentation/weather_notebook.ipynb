{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather augmentation\n",
    "Based on Boroughs:\n",
    "| Borough       | Latitude   | Longitude   |\n",
    "|---------------|------------|-------------|\n",
    "| The Bronx     | 40.8448° N | 73.8648° W  |\n",
    "| Brooklyn      | 40.6782° N | 73.9442° W  |\n",
    "| Manhattan     | 40.7831° N | 73.9712° W  |\n",
    "| Queens        | 40.7282° N | 73.7949° W  |\n",
    "| Staten Island | 40.5795° N | 74.1502° W  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from meteostat import Hourly\n",
    "from meteostat import Point\n",
    "\n",
    "base_path = \"../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs_locations = {\n",
    "    \"bronx\": Point(40.8448, -73.8648),\n",
    "    \"brooklyn\": Point(40.6782, -73.9442),\n",
    "    \"manhattan\": Point(40.7831, -73.9712),\n",
    "    \"queens\": Point(40.7282, -73.7949),\n",
    "    \"staten_island\": Point(40.5795, -74.1502)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve weather data from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snow\n",
      "NaN    508885\n",
      "Name: count, dtype: int64\n",
      "wpgt\n",
      "NaN    508885\n",
      "Name: count, dtype: int64\n",
      "tsun\n",
      "NaN    508885\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for each boroughs, get the weather hourly data from 2014 to today and save it in a csv file based on the borough name\n",
    "weather_data = pd.DataFrame()\n",
    "for borough, location in boroughs_locations.items():\n",
    "    data = Hourly(location, start=datetime(2013, 1, 1), end=datetime.now())\n",
    "    data = data.fetch()\n",
    "    data[\"borough\"] = borough\n",
    "    weather_data = pd.concat([weather_data, data])\n",
    "\n",
    "weather_data = weather_data.reset_index()\n",
    "weather_data = weather_data.rename(columns={\"time\": \"date\"})\n",
    "weather_data[\"date\"] = pd.to_datetime(weather_data[\"date\"])\n",
    "weather_data[\"hour\"] = weather_data[\"date\"].dt.hour\n",
    "weather_data[\"date\"] = weather_data[\"date\"].dt.date\n",
    "\n",
    "print(weather_data['snow'].value_counts(dropna=False)) # NEVER SNOW?\n",
    "print(weather_data['wpgt'].value_counts(dropna=False)) # NEVER WIND?\n",
    "print(weather_data['tsun'].value_counts(dropna=False)) # No meaningful data\n",
    "\n",
    "weather_data = weather_data.drop(columns=[\"snow\", \"wpgt\", \"tsun\"])\n",
    "\n",
    "borough_to_code = {\n",
    "  'manhattan': 1,\n",
    "  'bronx': 2,\n",
    "  'brooklyn': 3,\n",
    "  'queens': 4,\n",
    "  'staten_island': 5\n",
    "}\n",
    "\n",
    "weather_data['borough'] = weather_data['borough'].map(borough_to_code)\n",
    "\n",
    "weather_data.to_parquet(f\"{base_path}/weather.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>coco</th>\n",
       "      <th>borough</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1013.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1012.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508880</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>21.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508881</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>22.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508882</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>24.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508883</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>24.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508884</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1016.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508885 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  temp  dwpt  rhum  prcp   wdir  wspd    pres  coco  \\\n",
       "0       2013-01-01   2.8  -5.6  54.0   NaN  230.0  16.6  1015.0   NaN   \n",
       "1       2013-01-01   2.8  -6.1  52.0   0.0  240.0  14.8  1013.5   NaN   \n",
       "2       2013-01-01   2.8  -6.1  52.0   0.0  240.0  16.6  1012.6   NaN   \n",
       "3       2013-01-01   3.3  -6.1  50.0   0.0  250.0  14.8  1012.2   NaN   \n",
       "4       2013-01-01   3.3  -5.6  52.0   0.0  250.0  20.5  1012.4   NaN   \n",
       "...            ...   ...   ...   ...   ...    ...   ...     ...   ...   \n",
       "508880  2024-08-11  21.4  16.1  72.0   0.0  339.0   5.8  1016.4   3.0   \n",
       "508881  2024-08-11  22.7  16.3  67.0   0.0  356.0   4.7  1016.3   3.0   \n",
       "508882  2024-08-11  24.2  15.9  60.0   0.0    1.0   3.2  1016.5   2.0   \n",
       "508883  2024-08-11  24.8  15.7  57.0   0.0  225.0   2.5  1016.6   3.0   \n",
       "508884  2024-08-11  25.8  14.9  51.0   0.0  228.0   7.9  1016.2   3.0   \n",
       "\n",
       "        borough  hour  \n",
       "0             2     0  \n",
       "1             2     1  \n",
       "2             2     2  \n",
       "3             2     3  \n",
       "4             2     4  \n",
       "...         ...   ...  \n",
       "508880        5    12  \n",
       "508881        5    13  \n",
       "508882        5    14  \n",
       "508883        5    15  \n",
       "508884        5    16  \n",
       "\n",
       "[508885 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_parquet(f\"{base_path}/weather.parquet\")\n",
    "\n",
    "sample = pd.read_parquet(f\"{base_path}/sample_cleaned_data.parquet\")\n",
    "sample[\"issue_date\"] = pd.to_datetime(sample[\"issue_date\"])\n",
    "sample[\"_date\"] = sample[\"issue_date\"].dt.date\n",
    "sample[\"_hour\"] = sample[\"issue_date\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on string and int64 columns for key 'violation_county'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# merge the sample data with the weather data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_hour\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mviolation_county\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhour\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mborough\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m merged_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mborough\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop)\n",
      "File \u001b[0;32m~/miniconda3/envs/bd39/lib/python3.9/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/miniconda3/envs/bd39/lib/python3.9/site-packages/pandas/core/reshape/merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/bd39/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1507\u001b[0m     ):\n\u001b[0;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on string and int64 columns for key 'violation_county'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "# merge the sample data with the weather data\n",
    "merged_data = pd.merge(sample, weather_data, left_on=[\"_date\", \"_hour\", \"violation_county\"], right_on=[\"date\", \"hour\", \"borough\"], how=\"left\")\n",
    "\n",
    "columns_to_drop = [col for col in merged_data.columns if col.startswith(\"_\")] + [\"date\", \"hour\", \"borough\"]\n",
    "merged_data = merged_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data shape: (1404261, 43)\n",
      "Merged data shape: (1404261, 49)\n"
     ]
    }
   ],
   "source": [
    "# count the merged data and data\n",
    "print(f\"Sample data shape: {sample.shape}\")\n",
    "print(f\"Merged data shape: {merged_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summons_number:\n",
      "0    5069663409\n",
      "1    7433097510\n",
      "2    1358115771\n",
      "Name: summons_number, dtype: int64\n",
      "\n",
      "  plate_id:\n",
      "0     HSP9388\n",
      "1    T466979C\n",
      "2     49722JG\n",
      "Name: plate_id, dtype: string\n",
      "\n",
      "  registration_state:\n",
      "0    PA\n",
      "1    NY\n",
      "2    NY\n",
      "Name: registration_state, dtype: string\n",
      "\n",
      "  plate_type:\n",
      "0    PAS\n",
      "1    OMT\n",
      "2    COM\n",
      "Name: plate_type, dtype: string\n",
      "\n",
      "  issue_date:\n",
      "0   2013-07-20 18:09:00\n",
      "1   2013-07-29 08:06:00\n",
      "2   2013-07-10 09:44:00\n",
      "Name: issue_date, dtype: datetime64[ns]\n",
      "\n",
      "  violation_code:\n",
      "0     7\n",
      "1    21\n",
      "2    19\n",
      "Name: violation_code, dtype: int64\n",
      "\n",
      "  vehicle_body_type:\n",
      "0      CP\n",
      "1    SUBN\n",
      "2     VAN\n",
      "Name: vehicle_body_type, dtype: string\n",
      "\n",
      "  vehicle_make:\n",
      "0    DODGE\n",
      "1    TOYOT\n",
      "2    MAZDA\n",
      "Name: vehicle_make, dtype: string\n",
      "\n",
      "  issuing_agency:\n",
      "0    V\n",
      "1    T\n",
      "2    X\n",
      "Name: issuing_agency, dtype: string\n",
      "\n",
      "  street_code1:\n",
      "0        0\n",
      "1    51090\n",
      "2        0\n",
      "Name: street_code1, dtype: int64\n",
      "\n",
      "  street_code2:\n",
      "0        0\n",
      "1    16490\n",
      "2        0\n",
      "Name: street_code2, dtype: int64\n",
      "\n",
      "  street_code3:\n",
      "0        0\n",
      "1    16590\n",
      "2        0\n",
      "Name: street_code3, dtype: int64\n",
      "\n",
      "  vehicle_expiration_date:\n",
      "0          NaT\n",
      "1   2014-06-30\n",
      "2          NaT\n",
      "Name: vehicle_expiration_date, dtype: datetime64[ns]\n",
      "\n",
      "  violation_location:\n",
      "0    <NA>\n",
      "1     102\n",
      "2    0007\n",
      "Name: violation_location, dtype: string\n",
      "\n",
      "  violation_precinct:\n",
      "0      0\n",
      "1    102\n",
      "2      7\n",
      "Name: violation_precinct, dtype: int64\n",
      "\n",
      "  issuer_precinct:\n",
      "0      0\n",
      "1    102\n",
      "2      7\n",
      "Name: issuer_precinct, dtype: int64\n",
      "\n",
      "  issuer_code:\n",
      "0         0\n",
      "1    350438\n",
      "2    901890\n",
      "Name: issuer_code, dtype: int64\n",
      "\n",
      "  issuer_command:\n",
      "0    <NA>\n",
      "1    T402\n",
      "2    0007\n",
      "Name: issuer_command, dtype: string\n",
      "\n",
      "  issuer_squad:\n",
      "0    <NA>\n",
      "1       L\n",
      "2    0000\n",
      "Name: issuer_squad, dtype: string\n",
      "\n",
      "  violation_county:\n",
      "0         None\n",
      "1       queens\n",
      "2    manhattan\n",
      "Name: violation_county, dtype: object\n",
      "\n",
      "  violation_in_front_of_or_opposite:\n",
      "0    <NA>\n",
      "1       F\n",
      "2       F\n",
      "Name: violation_in_front_of_or_opposite, dtype: string\n",
      "\n",
      "  house_number:\n",
      "0    <NA>\n",
      "1    7903\n",
      "2    <NA>\n",
      "Name: house_number, dtype: string\n",
      "\n",
      "  street_name:\n",
      "0    EASTERN PKWY.(E)@UTI\n",
      "1             Jamaica Ave\n",
      "2        N/S OF MURRAY ST\n",
      "Name: street_name, dtype: string\n",
      "\n",
      "  intersecting_street:\n",
      "0     CA AVE.-K6-3\n",
      "1             <NA>\n",
      "2    WEST BROADWAY\n",
      "Name: intersecting_street, dtype: string\n",
      "\n",
      "  date_first_observed:\n",
      "0   NaT\n",
      "1   NaT\n",
      "2   NaT\n",
      "Name: date_first_observed, dtype: datetime64[ns]\n",
      "\n",
      "  law_section:\n",
      "0    1111\n",
      "1     408\n",
      "2     408\n",
      "Name: law_section, dtype: int64\n",
      "\n",
      "  sub_division:\n",
      "0     D\n",
      "1    d1\n",
      "2    I4\n",
      "Name: sub_division, dtype: string\n",
      "\n",
      "  violation_legal_code:\n",
      "0       T\n",
      "1    <NA>\n",
      "2    <NA>\n",
      "Name: violation_legal_code, dtype: string\n",
      "\n",
      "  days_parking_in_effect:\n",
      "0       <NA>\n",
      "1          Y\n",
      "2    BBBBBBB\n",
      "Name: days_parking_in_effect, dtype: string\n",
      "\n",
      "  from_hours_in_effect:\n",
      "0     <NA>\n",
      "1    0800A\n",
      "2      ALL\n",
      "Name: from_hours_in_effect, dtype: string\n",
      "\n",
      "  to_hours_in_effect:\n",
      "0     <NA>\n",
      "1    0830A\n",
      "2      ALL\n",
      "Name: to_hours_in_effect, dtype: string\n",
      "\n",
      "  vehicle_color:\n",
      "0    <NA>\n",
      "1    GREY\n",
      "2      BR\n",
      "Name: vehicle_color, dtype: string\n",
      "\n",
      "  unregistered_vehicle:\n",
      "0    <NA>\n",
      "1    <NA>\n",
      "2       0\n",
      "Name: unregistered_vehicle, dtype: string\n",
      "\n",
      "  vehicle_year:\n",
      "0    1998\n",
      "1    2013\n",
      "2    1995\n",
      "Name: vehicle_year, dtype: int64\n",
      "\n",
      "  meter_number:\n",
      "0    <NA>\n",
      "1    <NA>\n",
      "2       -\n",
      "Name: meter_number, dtype: string\n",
      "\n",
      "  feet_from_curb:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: feet_from_curb, dtype: int64\n",
      "\n",
      "  violation_post_code:\n",
      "0    <NA>\n",
      "1     H -\n",
      "2    <NA>\n",
      "Name: violation_post_code, dtype: string\n",
      "\n",
      "  violation_description:\n",
      "0    FAILURE TO STOP AT RED LIGHT\n",
      "1    21-No Parking (street clean)\n",
      "2                            <NA>\n",
      "Name: violation_description, dtype: string\n",
      "\n",
      "  no_standing_or_stopping_violation:\n",
      "0    <NA>\n",
      "1    <NA>\n",
      "2    <NA>\n",
      "Name: no_standing_or_stopping_violation, dtype: string\n",
      "\n",
      "  hydrant_violation:\n",
      "0    <NA>\n",
      "1    <NA>\n",
      "2    <NA>\n",
      "Name: hydrant_violation, dtype: string\n",
      "\n",
      "  double_parking_violation:\n",
      "0    <NA>\n",
      "1    <NA>\n",
      "2    <NA>\n",
      "Name: double_parking_violation, dtype: string\n",
      "\n",
      "  temp:\n",
      "0     NaN\n",
      "1    22.2\n",
      "2    23.9\n",
      "Name: temp, dtype: float64\n",
      "\n",
      "  dwpt:\n",
      "0     NaN\n",
      "1    20.7\n",
      "2    21.0\n",
      "Name: dwpt, dtype: float64\n",
      "\n",
      "  rhum:\n",
      "0     NaN\n",
      "1    91.0\n",
      "2    84.0\n",
      "Name: rhum, dtype: float64\n",
      "\n",
      "  prcp:\n",
      "0    NaN\n",
      "1    0.0\n",
      "2    0.0\n",
      "Name: prcp, dtype: float64\n",
      "\n",
      "  wdir:\n",
      "0      NaN\n",
      "1    320.0\n",
      "2    190.0\n",
      "Name: wdir, dtype: float64\n",
      "\n",
      "  wspd:\n",
      "0     NaN\n",
      "1    13.0\n",
      "2     9.4\n",
      "Name: wspd, dtype: float64\n",
      "\n",
      "  pres:\n",
      "0       NaN\n",
      "1    1015.5\n",
      "2    1014.3\n",
      "Name: pres, dtype: float64\n",
      "\n",
      "  coco:\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "Name: coco, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in merged_data.columns:\n",
    "    print(f\"  {col}:\\n{merged_data[col].head(3)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
